{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cef354cf",
   "metadata": {},
   "source": [
    "## 모델의 성능 향상시키기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7ce9cc",
   "metadata": {},
   "source": [
    "### 1. 데이터의 확인과 검증셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4ea2153a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6492</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.039</td>\n",
       "      <td>24.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6493</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>57.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6494</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.041</td>\n",
       "      <td>30.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6495</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.022</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.8</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6496</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.020</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6497 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1     2    3      4     5      6        7     8     9     10  \\\n",
       "0      7.4  0.70  0.00  1.9  0.076  11.0   34.0  0.99780  3.51  0.56   9.4   \n",
       "1      7.8  0.88  0.00  2.6  0.098  25.0   67.0  0.99680  3.20  0.68   9.8   \n",
       "2      7.8  0.76  0.04  2.3  0.092  15.0   54.0  0.99700  3.26  0.65   9.8   \n",
       "3     11.2  0.28  0.56  1.9  0.075  17.0   60.0  0.99800  3.16  0.58   9.8   \n",
       "4      7.4  0.70  0.00  1.9  0.076  11.0   34.0  0.99780  3.51  0.56   9.4   \n",
       "...    ...   ...   ...  ...    ...   ...    ...      ...   ...   ...   ...   \n",
       "6492   6.2  0.21  0.29  1.6  0.039  24.0   92.0  0.99114  3.27  0.50  11.2   \n",
       "6493   6.6  0.32  0.36  8.0  0.047  57.0  168.0  0.99490  3.15  0.46   9.6   \n",
       "6494   6.5  0.24  0.19  1.2  0.041  30.0  111.0  0.99254  2.99  0.46   9.4   \n",
       "6495   5.5  0.29  0.30  1.1  0.022  20.0  110.0  0.98869  3.34  0.38  12.8   \n",
       "6496   6.0  0.21  0.38  0.8  0.020  22.0   98.0  0.98941  3.26  0.32  11.8   \n",
       "\n",
       "      11  12  \n",
       "0      5   1  \n",
       "1      5   1  \n",
       "2      5   1  \n",
       "3      6   1  \n",
       "4      5   1  \n",
       "...   ..  ..  \n",
       "6492   6   0  \n",
       "6493   5   0  \n",
       "6494   6   0  \n",
       "6495   7   0  \n",
       "6496   6   0  \n",
       "\n",
       "[6497 rows x 13 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('C:\\강의 교안\\딥러닝\\wine.csv', header=None)\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4c11f719",
   "metadata": {},
   "outputs": [],
   "source": [
    "#와인의 속성을 X로 와인의 분류를 Y로 저장함\n",
    "X = df.iloc[:, 0:12]\n",
    "Y = df.iloc[:, 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "51867660",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python313\\site-packages\\keras\\src\\layers\\core\\dense.py:106: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">390</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">372</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">104</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_24 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │           \u001b[38;5;34m390\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_25 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │           \u001b[38;5;34m372\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_26 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m104\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_27 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m9\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">875</span> (3.42 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m875\u001b[0m (3.42 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">875</span> (3.42 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m875\u001b[0m (3.42 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#학습셋과 테스트셋으로 나눔\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.2, shuffle=True)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim = 12, activation = 'relu'))\n",
    "model.add(Dense(12, activation = 'relu'))\n",
    "model.add(Dense(8, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9908c4c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.2479 - loss: 42.4925 - val_accuracy: 0.2477 - val_loss: 35.3546\n",
      "Epoch 2/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2479 - loss: 29.6165 - val_accuracy: 0.2477 - val_loss: 22.6450\n",
      "Epoch 3/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2479 - loss: 17.1587 - val_accuracy: 0.2477 - val_loss: 10.0752\n",
      "Epoch 4/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2628 - loss: 5.1806 - val_accuracy: 0.7108 - val_loss: 0.6776\n",
      "Epoch 5/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7583 - loss: 0.8994 - val_accuracy: 0.7600 - val_loss: 1.1443\n",
      "Epoch 6/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7647 - loss: 1.1550 - val_accuracy: 0.7723 - val_loss: 1.0932\n",
      "Epoch 7/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7834 - loss: 0.9938 - val_accuracy: 0.7931 - val_loss: 0.8114\n",
      "Epoch 8/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7829 - loss: 0.7286 - val_accuracy: 0.7523 - val_loss: 0.6553\n",
      "Epoch 9/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7603 - loss: 0.6352 - val_accuracy: 0.8138 - val_loss: 0.5486\n",
      "Epoch 10/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8193 - loss: 0.5412 - val_accuracy: 0.8354 - val_loss: 0.4838\n",
      "Epoch 11/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8317 - loss: 0.4558 - val_accuracy: 0.8362 - val_loss: 0.4064\n",
      "Epoch 12/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8406 - loss: 0.3998 - val_accuracy: 0.8615 - val_loss: 0.3649\n",
      "Epoch 13/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8609 - loss: 0.3597 - val_accuracy: 0.8762 - val_loss: 0.3383\n",
      "Epoch 14/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8753 - loss: 0.3308 - val_accuracy: 0.8838 - val_loss: 0.3147\n",
      "Epoch 15/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8858 - loss: 0.3057 - val_accuracy: 0.8908 - val_loss: 0.2934\n",
      "Epoch 16/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8958 - loss: 0.2817 - val_accuracy: 0.8969 - val_loss: 0.2747\n",
      "Epoch 17/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9043 - loss: 0.2621 - val_accuracy: 0.9015 - val_loss: 0.2566\n",
      "Epoch 18/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9115 - loss: 0.2471 - val_accuracy: 0.9077 - val_loss: 0.2434\n",
      "Epoch 19/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9117 - loss: 0.2344 - val_accuracy: 0.9131 - val_loss: 0.2380\n",
      "Epoch 20/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9156 - loss: 0.2281 - val_accuracy: 0.9123 - val_loss: 0.2351\n",
      "Epoch 21/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9169 - loss: 0.2238 - val_accuracy: 0.9108 - val_loss: 0.2309\n",
      "Epoch 22/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9215 - loss: 0.2133 - val_accuracy: 0.9208 - val_loss: 0.2218\n",
      "Epoch 23/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9281 - loss: 0.2046 - val_accuracy: 0.9246 - val_loss: 0.2161\n",
      "Epoch 24/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9297 - loss: 0.1995 - val_accuracy: 0.9300 - val_loss: 0.2138\n",
      "Epoch 25/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9335 - loss: 0.1963 - val_accuracy: 0.9300 - val_loss: 0.2114\n",
      "Epoch 26/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9343 - loss: 0.1926 - val_accuracy: 0.9300 - val_loss: 0.2086\n",
      "Epoch 27/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9361 - loss: 0.1893 - val_accuracy: 0.9354 - val_loss: 0.2061\n",
      "Epoch 28/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9371 - loss: 0.1857 - val_accuracy: 0.9338 - val_loss: 0.2027\n",
      "Epoch 29/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9371 - loss: 0.1831 - val_accuracy: 0.9362 - val_loss: 0.2002\n",
      "Epoch 30/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9376 - loss: 0.1805 - val_accuracy: 0.9362 - val_loss: 0.1977\n",
      "Epoch 31/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9374 - loss: 0.1794 - val_accuracy: 0.9377 - val_loss: 0.1958\n",
      "Epoch 32/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9397 - loss: 0.1800 - val_accuracy: 0.9362 - val_loss: 0.1934\n",
      "Epoch 33/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9379 - loss: 0.1761 - val_accuracy: 0.9369 - val_loss: 0.1914\n",
      "Epoch 34/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9415 - loss: 0.1724 - val_accuracy: 0.9377 - val_loss: 0.1902\n",
      "Epoch 35/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9415 - loss: 0.1713 - val_accuracy: 0.9377 - val_loss: 0.1880\n",
      "Epoch 36/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9430 - loss: 0.1702 - val_accuracy: 0.9377 - val_loss: 0.1866\n",
      "Epoch 37/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9428 - loss: 0.1681 - val_accuracy: 0.9385 - val_loss: 0.1855\n",
      "Epoch 38/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9441 - loss: 0.1661 - val_accuracy: 0.9392 - val_loss: 0.1841\n",
      "Epoch 39/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9438 - loss: 0.1645 - val_accuracy: 0.9400 - val_loss: 0.1826\n",
      "Epoch 40/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9464 - loss: 0.1626 - val_accuracy: 0.9415 - val_loss: 0.1809\n",
      "Epoch 41/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9464 - loss: 0.1605 - val_accuracy: 0.9400 - val_loss: 0.1796\n",
      "Epoch 42/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9469 - loss: 0.1594 - val_accuracy: 0.9408 - val_loss: 0.1776\n",
      "Epoch 43/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9477 - loss: 0.1572 - val_accuracy: 0.9415 - val_loss: 0.1763\n",
      "Epoch 44/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9489 - loss: 0.1560 - val_accuracy: 0.9400 - val_loss: 0.1741\n",
      "Epoch 45/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9507 - loss: 0.1538 - val_accuracy: 0.9408 - val_loss: 0.1719\n",
      "Epoch 46/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9500 - loss: 0.1521 - val_accuracy: 0.9408 - val_loss: 0.1701\n",
      "Epoch 47/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9515 - loss: 0.1502 - val_accuracy: 0.9408 - val_loss: 0.1684\n",
      "Epoch 48/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9507 - loss: 0.1505 - val_accuracy: 0.9415 - val_loss: 0.1673\n",
      "Epoch 49/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9530 - loss: 0.1471 - val_accuracy: 0.9408 - val_loss: 0.1682\n",
      "Epoch 50/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9505 - loss: 0.1464 - val_accuracy: 0.9423 - val_loss: 0.1647\n"
     ]
    }
   ],
   "source": [
    "#모델을 컴파일함\n",
    "model.compile(loss ='binary_crossentropy', optimizer ='adam', metrics = ['accuracy'])\n",
    "\n",
    "#모델을 실행함\n",
    "history = model.fit(X_train, Y_train, epochs =50, batch_size =500, validation_split =0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2e200e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9492 - loss: 0.1532 \n",
      "Test accuracy: 0.9492307901382446\n"
     ]
    }
   ],
   "source": [
    "#테스트 결과를 출력\n",
    "score = model.evaluate(X_test, Y_test)\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89190035",
   "metadata": {},
   "source": [
    "## 2. 모델 업데이트하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bbe417",
   "metadata": {},
   "source": [
    "### 기본 코드 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "937a10dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python313\\site-packages\\keras\\src\\layers\\core\\dense.py:106: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_7\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">390</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">372</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">104</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_28 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │           \u001b[38;5;34m390\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_29 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │           \u001b[38;5;34m372\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_30 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m104\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_31 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m9\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">875</span> (3.42 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m875\u001b[0m (3.42 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">875</span> (3.42 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m875\u001b[0m (3.42 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#와인 데이터를 불러옴\n",
    "df = pd.read_csv('C:\\강의 교안\\딥러닝\\wine.csv', header=None)\n",
    "\n",
    "#와인의 속성을 X로 와인의 분류를 Y로 저장\n",
    "X=df.iloc[:,0:12]\n",
    "Y=df.iloc[:,12]\n",
    "\n",
    "#학습셋과 테스트셋으로 나눔\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size =0.2, shuffle = True)\n",
    "\n",
    "#모델 구조 설정\n",
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim=12, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "#모델을 컴파일함\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8638ed3c",
   "metadata": {},
   "source": [
    "### 모델의 저장 설정 및 실행\n",
    "이전에는 학습이 끝난 뒤에 맨 마지막 것만 저장했다면, 중간중간 과정을 기록으로 남김"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2088990f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: saving model to ./data/model/all/01-0.7754.keras\n",
      "\n",
      "Epoch 1: finished saving model to ./data/model/all/01-0.7754.keras\n",
      "\n",
      "Epoch 2: saving model to ./data/model/all/02-0.7800.keras\n",
      "\n",
      "Epoch 2: finished saving model to ./data/model/all/02-0.7800.keras\n",
      "\n",
      "Epoch 3: saving model to ./data/model/all/03-0.8169.keras\n",
      "\n",
      "Epoch 3: finished saving model to ./data/model/all/03-0.8169.keras\n",
      "\n",
      "Epoch 4: saving model to ./data/model/all/04-0.9146.keras\n",
      "\n",
      "Epoch 4: finished saving model to ./data/model/all/04-0.9146.keras\n",
      "\n",
      "Epoch 5: saving model to ./data/model/all/05-0.9215.keras\n",
      "\n",
      "Epoch 5: finished saving model to ./data/model/all/05-0.9215.keras\n",
      "\n",
      "Epoch 6: saving model to ./data/model/all/06-0.9185.keras\n",
      "\n",
      "Epoch 6: finished saving model to ./data/model/all/06-0.9185.keras\n",
      "\n",
      "Epoch 7: saving model to ./data/model/all/07-0.9292.keras\n",
      "\n",
      "Epoch 7: finished saving model to ./data/model/all/07-0.9292.keras\n",
      "\n",
      "Epoch 8: saving model to ./data/model/all/08-0.9392.keras\n",
      "\n",
      "Epoch 8: finished saving model to ./data/model/all/08-0.9392.keras\n",
      "\n",
      "Epoch 9: saving model to ./data/model/all/09-0.9400.keras\n",
      "\n",
      "Epoch 9: finished saving model to ./data/model/all/09-0.9400.keras\n",
      "\n",
      "Epoch 10: saving model to ./data/model/all/10-0.9400.keras\n",
      "\n",
      "Epoch 10: finished saving model to ./data/model/all/10-0.9400.keras\n",
      "\n",
      "Epoch 11: saving model to ./data/model/all/11-0.9415.keras\n",
      "\n",
      "Epoch 11: finished saving model to ./data/model/all/11-0.9415.keras\n",
      "\n",
      "Epoch 12: saving model to ./data/model/all/12-0.9438.keras\n",
      "\n",
      "Epoch 12: finished saving model to ./data/model/all/12-0.9438.keras\n",
      "\n",
      "Epoch 13: saving model to ./data/model/all/13-0.9431.keras\n",
      "\n",
      "Epoch 13: finished saving model to ./data/model/all/13-0.9431.keras\n",
      "\n",
      "Epoch 14: saving model to ./data/model/all/14-0.9438.keras\n",
      "\n",
      "Epoch 14: finished saving model to ./data/model/all/14-0.9438.keras\n",
      "\n",
      "Epoch 15: saving model to ./data/model/all/15-0.9438.keras\n",
      "\n",
      "Epoch 15: finished saving model to ./data/model/all/15-0.9438.keras\n",
      "\n",
      "Epoch 16: saving model to ./data/model/all/16-0.9446.keras\n",
      "\n",
      "Epoch 16: finished saving model to ./data/model/all/16-0.9446.keras\n",
      "\n",
      "Epoch 17: saving model to ./data/model/all/17-0.9431.keras\n",
      "\n",
      "Epoch 17: finished saving model to ./data/model/all/17-0.9431.keras\n",
      "\n",
      "Epoch 18: saving model to ./data/model/all/18-0.9431.keras\n",
      "\n",
      "Epoch 18: finished saving model to ./data/model/all/18-0.9431.keras\n",
      "\n",
      "Epoch 19: saving model to ./data/model/all/19-0.9462.keras\n",
      "\n",
      "Epoch 19: finished saving model to ./data/model/all/19-0.9462.keras\n",
      "\n",
      "Epoch 20: saving model to ./data/model/all/20-0.9423.keras\n",
      "\n",
      "Epoch 20: finished saving model to ./data/model/all/20-0.9423.keras\n",
      "\n",
      "Epoch 21: saving model to ./data/model/all/21-0.9469.keras\n",
      "\n",
      "Epoch 21: finished saving model to ./data/model/all/21-0.9469.keras\n",
      "\n",
      "Epoch 22: saving model to ./data/model/all/22-0.9454.keras\n",
      "\n",
      "Epoch 22: finished saving model to ./data/model/all/22-0.9454.keras\n",
      "\n",
      "Epoch 23: saving model to ./data/model/all/23-0.9454.keras\n",
      "\n",
      "Epoch 23: finished saving model to ./data/model/all/23-0.9454.keras\n",
      "\n",
      "Epoch 24: saving model to ./data/model/all/24-0.9492.keras\n",
      "\n",
      "Epoch 24: finished saving model to ./data/model/all/24-0.9492.keras\n",
      "\n",
      "Epoch 25: saving model to ./data/model/all/25-0.9469.keras\n",
      "\n",
      "Epoch 25: finished saving model to ./data/model/all/25-0.9469.keras\n",
      "\n",
      "Epoch 26: saving model to ./data/model/all/26-0.9492.keras\n",
      "\n",
      "Epoch 26: finished saving model to ./data/model/all/26-0.9492.keras\n",
      "\n",
      "Epoch 27: saving model to ./data/model/all/27-0.9469.keras\n",
      "\n",
      "Epoch 27: finished saving model to ./data/model/all/27-0.9469.keras\n",
      "\n",
      "Epoch 28: saving model to ./data/model/all/28-0.9500.keras\n",
      "\n",
      "Epoch 28: finished saving model to ./data/model/all/28-0.9500.keras\n",
      "\n",
      "Epoch 29: saving model to ./data/model/all/29-0.9469.keras\n",
      "\n",
      "Epoch 29: finished saving model to ./data/model/all/29-0.9469.keras\n",
      "\n",
      "Epoch 30: saving model to ./data/model/all/30-0.9477.keras\n",
      "\n",
      "Epoch 30: finished saving model to ./data/model/all/30-0.9477.keras\n",
      "\n",
      "Epoch 31: saving model to ./data/model/all/31-0.9477.keras\n",
      "\n",
      "Epoch 31: finished saving model to ./data/model/all/31-0.9477.keras\n",
      "\n",
      "Epoch 32: saving model to ./data/model/all/32-0.9477.keras\n",
      "\n",
      "Epoch 32: finished saving model to ./data/model/all/32-0.9477.keras\n",
      "\n",
      "Epoch 33: saving model to ./data/model/all/33-0.9508.keras\n",
      "\n",
      "Epoch 33: finished saving model to ./data/model/all/33-0.9508.keras\n",
      "\n",
      "Epoch 34: saving model to ./data/model/all/34-0.9485.keras\n",
      "\n",
      "Epoch 34: finished saving model to ./data/model/all/34-0.9485.keras\n",
      "\n",
      "Epoch 35: saving model to ./data/model/all/35-0.9485.keras\n",
      "\n",
      "Epoch 35: finished saving model to ./data/model/all/35-0.9485.keras\n",
      "\n",
      "Epoch 36: saving model to ./data/model/all/36-0.9500.keras\n",
      "\n",
      "Epoch 36: finished saving model to ./data/model/all/36-0.9500.keras\n",
      "\n",
      "Epoch 37: saving model to ./data/model/all/37-0.9508.keras\n",
      "\n",
      "Epoch 37: finished saving model to ./data/model/all/37-0.9508.keras\n",
      "\n",
      "Epoch 38: saving model to ./data/model/all/38-0.9500.keras\n",
      "\n",
      "Epoch 38: finished saving model to ./data/model/all/38-0.9500.keras\n",
      "\n",
      "Epoch 39: saving model to ./data/model/all/39-0.9492.keras\n",
      "\n",
      "Epoch 39: finished saving model to ./data/model/all/39-0.9492.keras\n",
      "\n",
      "Epoch 40: saving model to ./data/model/all/40-0.9500.keras\n",
      "\n",
      "Epoch 40: finished saving model to ./data/model/all/40-0.9500.keras\n",
      "\n",
      "Epoch 41: saving model to ./data/model/all/41-0.9515.keras\n",
      "\n",
      "Epoch 41: finished saving model to ./data/model/all/41-0.9515.keras\n",
      "\n",
      "Epoch 42: saving model to ./data/model/all/42-0.9500.keras\n",
      "\n",
      "Epoch 42: finished saving model to ./data/model/all/42-0.9500.keras\n",
      "\n",
      "Epoch 43: saving model to ./data/model/all/43-0.9515.keras\n",
      "\n",
      "Epoch 43: finished saving model to ./data/model/all/43-0.9515.keras\n",
      "\n",
      "Epoch 44: saving model to ./data/model/all/44-0.9485.keras\n",
      "\n",
      "Epoch 44: finished saving model to ./data/model/all/44-0.9485.keras\n",
      "\n",
      "Epoch 45: saving model to ./data/model/all/45-0.9531.keras\n",
      "\n",
      "Epoch 45: finished saving model to ./data/model/all/45-0.9531.keras\n",
      "\n",
      "Epoch 46: saving model to ./data/model/all/46-0.9477.keras\n",
      "\n",
      "Epoch 46: finished saving model to ./data/model/all/46-0.9477.keras\n",
      "\n",
      "Epoch 47: saving model to ./data/model/all/47-0.9515.keras\n",
      "\n",
      "Epoch 47: finished saving model to ./data/model/all/47-0.9515.keras\n",
      "\n",
      "Epoch 48: saving model to ./data/model/all/48-0.9492.keras\n",
      "\n",
      "Epoch 48: finished saving model to ./data/model/all/48-0.9492.keras\n",
      "\n",
      "Epoch 49: saving model to ./data/model/all/49-0.9485.keras\n",
      "\n",
      "Epoch 49: finished saving model to ./data/model/all/49-0.9485.keras\n",
      "\n",
      "Epoch 50: saving model to ./data/model/all/50-0.9515.keras\n",
      "\n",
      "Epoch 50: finished saving model to ./data/model/all/50-0.9515.keras\n"
     ]
    }
   ],
   "source": [
    "#모델 저장 조건을 설정\n",
    "modelpath = './data/model/all/{epoch:02d}-{val_accuracy:.4f}.keras'\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, verbose=1)\n",
    "\n",
    "#모델을 실행함\n",
    "#validation_split=0.25 : 25%는 검증용으로 사용 (모의고사를 위해 공부할 책 X_train의 일부를 떼어내기)\n",
    "    #학습(Train)이 잘 되고 있는지, 과적합을 매 Epoch마다 실시\n",
    "histroy=model.fit(X_train, Y_train, epochs=50, batch_size=500, validation_split=0.25, verbose=0, callbacks=[checkpointer])\n",
    "#callback(중간 개입자, Epoch끝날 때마다 특정 함수 실행): val_accuracy를 볼 때마다, 그 순간의 모델을 파일로 저장해주는 자동 저장장치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3c9096d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 995us/step - accuracy: 0.9585 - loss: 0.1344\n",
      "Test accuracy: 0.9584615230560303\n"
     ]
    }
   ],
   "source": [
    "#테스트 결과를 출력 \n",
    "score = model.evaluate(X_test, Y_test)\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4760843e",
   "metadata": {},
   "source": [
    "## 3. 그래프로 과적합 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "275c0a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import LambdaCallback #직접 만든 함수def 를 학습 도중 사용할 수 있는 콜백 형태로 바꿔주는 도구\n",
    "import tensorflow as tf\n",
    "\n",
    "def custom_log(epoch, logs): #몇번째 epoch인지, 성적표 \n",
    "    if(epoch+1)%50 ==0: #50으로 나누었을 때 나머지가 0이냐? -> 50회, 100회, 150회 타이밍에 출력\n",
    "        #50번에 한 번만 출력하는 필터링 \n",
    "        num_batches = len(X_train)//500 #전체 데이터를 500(batch_size를 500으로 가정)으로 나눠서, 한 바퀴 돌 때 배치가 몇 덩어리인지 계산해\n",
    "        print(f\"Epoch {epoch+1}/2000\")\n",
    "        tf.print(f\"{num_batches}/{num_batches}')--------------------\"\n",
    "        f\"accuracy: {logs['accuracy']:.4f}' - loss: {logs['loss']:.4f}-\"\n",
    "        f\"val_accuracy: {logs['val_accuracy']:.4f}' - val_loss: {logs['val_loss']:.4f}\")\n",
    "show_status = LambdaCallback(on_epoch_end=custom_log)\n",
    "#oo_epoch_end = custom_log: custom_log 함수를 Epoch이 끝날 때마다 실행시켜줘\n",
    "#custom_log 함수를 케라스 모델이 알 수 있는 'Callback형태'로 포장해주는 도구가 LambdaCallback 임 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5e58ed5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/2000\n",
      "10/10')--------------------accuracy: 0.9715' - loss: 0.0901-val_accuracy: 0.9685' - val_loss: 0.0949\n",
      "Epoch 100/2000\n",
      "10/10')--------------------accuracy: 0.9795' - loss: 0.0705-val_accuracy: 0.9785' - val_loss: 0.0758\n",
      "Epoch 150/2000\n",
      "10/10')--------------------accuracy: 0.9831' - loss: 0.0597-val_accuracy: 0.9800' - val_loss: 0.0705\n",
      "Epoch 200/2000\n",
      "10/10')--------------------accuracy: 0.9836' - loss: 0.0530-val_accuracy: 0.9831' - val_loss: 0.0645\n",
      "Epoch 250/2000\n",
      "10/10')--------------------accuracy: 0.9841' - loss: 0.0497-val_accuracy: 0.9854' - val_loss: 0.0647\n",
      "Epoch 300/2000\n",
      "10/10')--------------------accuracy: 0.9851' - loss: 0.0462-val_accuracy: 0.9846' - val_loss: 0.0618\n",
      "Epoch 350/2000\n",
      "10/10')--------------------accuracy: 0.9869' - loss: 0.0466-val_accuracy: 0.9869' - val_loss: 0.0565\n",
      "Epoch 400/2000\n",
      "10/10')--------------------accuracy: 0.9882' - loss: 0.0442-val_accuracy: 0.9862' - val_loss: 0.0558\n",
      "Epoch 450/2000\n",
      "10/10')--------------------accuracy: 0.9887' - loss: 0.0420-val_accuracy: 0.9877' - val_loss: 0.0540\n",
      "Epoch 500/2000\n",
      "10/10')--------------------accuracy: 0.9892' - loss: 0.0412-val_accuracy: 0.9885' - val_loss: 0.0541\n",
      "Epoch 550/2000\n",
      "10/10')--------------------accuracy: 0.9902' - loss: 0.0404-val_accuracy: 0.9885' - val_loss: 0.0528\n",
      "Epoch 600/2000\n",
      "10/10')--------------------accuracy: 0.9908' - loss: 0.0399-val_accuracy: 0.9869' - val_loss: 0.0543\n",
      "Epoch 650/2000\n",
      "10/10')--------------------accuracy: 0.9874' - loss: 0.0433-val_accuracy: 0.9869' - val_loss: 0.0545\n",
      "Epoch 700/2000\n",
      "10/10')--------------------accuracy: 0.9900' - loss: 0.0384-val_accuracy: 0.9885' - val_loss: 0.0553\n",
      "Epoch 750/2000\n",
      "10/10')--------------------accuracy: 0.9908' - loss: 0.0363-val_accuracy: 0.9892' - val_loss: 0.0537\n",
      "Epoch 800/2000\n",
      "10/10')--------------------accuracy: 0.9895' - loss: 0.0388-val_accuracy: 0.9892' - val_loss: 0.0545\n",
      "Epoch 850/2000\n",
      "10/10')--------------------accuracy: 0.9905' - loss: 0.0379-val_accuracy: 0.9869' - val_loss: 0.0572\n",
      "Epoch 900/2000\n",
      "10/10')--------------------accuracy: 0.9913' - loss: 0.0345-val_accuracy: 0.9862' - val_loss: 0.0583\n",
      "Epoch 950/2000\n",
      "10/10')--------------------accuracy: 0.9900' - loss: 0.0386-val_accuracy: 0.9862' - val_loss: 0.0635\n",
      "Epoch 1000/2000\n",
      "10/10')--------------------accuracy: 0.9905' - loss: 0.0353-val_accuracy: 0.9885' - val_loss: 0.0585\n",
      "Epoch 1050/2000\n",
      "10/10')--------------------accuracy: 0.9902' - loss: 0.0373-val_accuracy: 0.9854' - val_loss: 0.0607\n",
      "Epoch 1100/2000\n",
      "10/10')--------------------accuracy: 0.9905' - loss: 0.0344-val_accuracy: 0.9892' - val_loss: 0.0581\n",
      "Epoch 1150/2000\n",
      "10/10')--------------------accuracy: 0.9908' - loss: 0.0328-val_accuracy: 0.9877' - val_loss: 0.0593\n",
      "Epoch 1200/2000\n",
      "10/10')--------------------accuracy: 0.9900' - loss: 0.0359-val_accuracy: 0.9862' - val_loss: 0.0611\n",
      "Epoch 1250/2000\n",
      "10/10')--------------------accuracy: 0.9910' - loss: 0.0335-val_accuracy: 0.9885' - val_loss: 0.0608\n",
      "Epoch 1300/2000\n",
      "10/10')--------------------accuracy: 0.9913' - loss: 0.0318-val_accuracy: 0.9862' - val_loss: 0.0610\n",
      "Epoch 1350/2000\n",
      "10/10')--------------------accuracy: 0.9908' - loss: 0.0326-val_accuracy: 0.9854' - val_loss: 0.0673\n",
      "Epoch 1400/2000\n",
      "10/10')--------------------accuracy: 0.9915' - loss: 0.0309-val_accuracy: 0.9869' - val_loss: 0.0643\n",
      "Epoch 1450/2000\n",
      "10/10')--------------------accuracy: 0.9915' - loss: 0.0311-val_accuracy: 0.9862' - val_loss: 0.0636\n",
      "Epoch 1500/2000\n",
      "10/10')--------------------accuracy: 0.9915' - loss: 0.0302-val_accuracy: 0.9862' - val_loss: 0.0636\n",
      "Epoch 1550/2000\n",
      "10/10')--------------------accuracy: 0.9923' - loss: 0.0296-val_accuracy: 0.9869' - val_loss: 0.0660\n",
      "Epoch 1600/2000\n",
      "10/10')--------------------accuracy: 0.9918' - loss: 0.0313-val_accuracy: 0.9846' - val_loss: 0.0672\n",
      "Epoch 1650/2000\n",
      "10/10')--------------------accuracy: 0.9923' - loss: 0.0302-val_accuracy: 0.9854' - val_loss: 0.0692\n",
      "Epoch 1700/2000\n",
      "10/10')--------------------accuracy: 0.9915' - loss: 0.0314-val_accuracy: 0.9869' - val_loss: 0.0716\n",
      "Epoch 1750/2000\n",
      "10/10')--------------------accuracy: 0.9926' - loss: 0.0290-val_accuracy: 0.9846' - val_loss: 0.0649\n",
      "Epoch 1800/2000\n",
      "10/10')--------------------accuracy: 0.9923' - loss: 0.0300-val_accuracy: 0.9823' - val_loss: 0.0716\n",
      "Epoch 1850/2000\n",
      "10/10')--------------------accuracy: 0.9918' - loss: 0.0284-val_accuracy: 0.9846' - val_loss: 0.0651\n",
      "Epoch 1900/2000\n",
      "10/10')--------------------accuracy: 0.9931' - loss: 0.0281-val_accuracy: 0.9838' - val_loss: 0.0649\n",
      "Epoch 1950/2000\n",
      "10/10')--------------------accuracy: 0.9920' - loss: 0.0281-val_accuracy: 0.9831' - val_loss: 0.0770\n",
      "Epoch 2000/2000\n",
      "10/10')--------------------accuracy: 0.9918' - loss: 0.0264-val_accuracy: 0.9831' - val_loss: 0.0718\n"
     ]
    }
   ],
   "source": [
    "#그래프 확인을 위한 긴 학습\n",
    "history=model.fit(X_train, Y_train, epochs=2000, batch_size=500, validation_split=0.25, verbose = 0, callbacks=show_status)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c42ccd30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.948678</td>\n",
       "      <td>0.136584</td>\n",
       "      <td>0.948462</td>\n",
       "      <td>0.127823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.950731</td>\n",
       "      <td>0.135242</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.127873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.948935</td>\n",
       "      <td>0.133055</td>\n",
       "      <td>0.950769</td>\n",
       "      <td>0.127089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.950218</td>\n",
       "      <td>0.131825</td>\n",
       "      <td>0.954615</td>\n",
       "      <td>0.126179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.950475</td>\n",
       "      <td>0.130714</td>\n",
       "      <td>0.950769</td>\n",
       "      <td>0.124377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.991789</td>\n",
       "      <td>0.027282</td>\n",
       "      <td>0.986154</td>\n",
       "      <td>0.069334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.992815</td>\n",
       "      <td>0.025797</td>\n",
       "      <td>0.983077</td>\n",
       "      <td>0.073687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.992558</td>\n",
       "      <td>0.026358</td>\n",
       "      <td>0.982308</td>\n",
       "      <td>0.068301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0.992045</td>\n",
       "      <td>0.026247</td>\n",
       "      <td>0.985385</td>\n",
       "      <td>0.066486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.991789</td>\n",
       "      <td>0.026432</td>\n",
       "      <td>0.983077</td>\n",
       "      <td>0.071753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      accuracy      loss  val_accuracy  val_loss\n",
       "0     0.948678  0.136584      0.948462  0.127823\n",
       "1     0.950731  0.135242      0.950000  0.127873\n",
       "2     0.948935  0.133055      0.950769  0.127089\n",
       "3     0.950218  0.131825      0.954615  0.126179\n",
       "4     0.950475  0.130714      0.950769  0.124377\n",
       "...        ...       ...           ...       ...\n",
       "1995  0.991789  0.027282      0.986154  0.069334\n",
       "1996  0.992815  0.025797      0.983077  0.073687\n",
       "1997  0.992558  0.026358      0.982308  0.068301\n",
       "1998  0.992045  0.026247      0.985385  0.066486\n",
       "1999  0.991789  0.026432      0.983077  0.071753\n",
       "\n",
       "[2000 rows x 4 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#history에 저장된 학습 결과를 확인\n",
    "hist_df=pd.DataFrame(history.history)\n",
    "hist_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8af9f2b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Y_vloss에 검증셋의 오차를 저장\n",
    "Y_vloss = hist_df ['val_loss']\n",
    "#Y_loss에 훈련셋의 오차를 저장\n",
    "Y_loss=hist_df['loss']\n",
    "#X값을 지정, 검증셋의 오차를 빨간색, 학습셋의 오차를 파란색으로 표시 \n",
    "X_len = np.arange(len(Y_loss))\n",
    "plt.plot(X_len, Y_vloss, \"o\", c=\"red\", markersize=2, label=\"Testset_loss\")\n",
    "plt.plot(X_len, Y_loss, \"o\", c=\"blue\", markersize=2, label =\"Trainset_loss\")\n",
    "\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06488b3",
   "metadata": {},
   "source": [
    "## 4. 학습의 중단\n",
    "### 기본 코드 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f4827260",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "39149a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "987aa374",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python313\\site-packages\\keras\\src\\layers\\core\\dense.py:106: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_9\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_9\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">390</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">372</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">104</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_36 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │           \u001b[38;5;34m390\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_37 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │           \u001b[38;5;34m372\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_38 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m104\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_39 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m9\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">875</span> (3.42 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m875\u001b[0m (3.42 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">875</span> (3.42 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m875\u001b[0m (3.42 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('C:\\강의 교안\\딥러닝\\wine.csv', header=None)\n",
    "\n",
    "\n",
    "X=df.iloc[:,0:12]\n",
    "Y=df.iloc[:,12]\n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size =0.2, shuffle=True)\n",
    "\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Dense(30, input_dim=12, activation='relu'))\n",
    "model.add(Dense(12, activation ='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0d1326",
   "metadata": {},
   "source": [
    "### 학습의 자동 중단 및 최적화 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1578f3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.3667 - loss: 3.8070 - val_accuracy: 0.7808 - val_loss: 0.4495\n",
      "Epoch 2/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7667 - loss: 0.6379 - val_accuracy: 0.7715 - val_loss: 0.8096\n",
      "Epoch 3/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7711 - loss: 0.7811 - val_accuracy: 0.7969 - val_loss: 0.7282\n",
      "Epoch 4/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8196 - loss: 0.5968 - val_accuracy: 0.8685 - val_loss: 0.4236\n",
      "Epoch 5/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9135 - loss: 0.3159 - val_accuracy: 0.8992 - val_loss: 0.2920\n",
      "Epoch 6/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8840 - loss: 0.2988 - val_accuracy: 0.9285 - val_loss: 0.2528\n",
      "Epoch 7/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9330 - loss: 0.2550 - val_accuracy: 0.9215 - val_loss: 0.2590\n",
      "Epoch 8/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9338 - loss: 0.2525 - val_accuracy: 0.9292 - val_loss: 0.2387\n",
      "Epoch 9/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9292 - loss: 0.2415 - val_accuracy: 0.9277 - val_loss: 0.2390\n",
      "Epoch 10/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9335 - loss: 0.2362 - val_accuracy: 0.9292 - val_loss: 0.2306\n",
      "Epoch 11/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9358 - loss: 0.2308 - val_accuracy: 0.9323 - val_loss: 0.2252\n",
      "Epoch 12/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9343 - loss: 0.2258 - val_accuracy: 0.9315 - val_loss: 0.2217\n",
      "Epoch 13/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9341 - loss: 0.2223 - val_accuracy: 0.9323 - val_loss: 0.2185\n",
      "Epoch 14/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9348 - loss: 0.2189 - val_accuracy: 0.9315 - val_loss: 0.2154\n",
      "Epoch 15/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9346 - loss: 0.2159 - val_accuracy: 0.9323 - val_loss: 0.2130\n",
      "Epoch 16/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9356 - loss: 0.2132 - val_accuracy: 0.9308 - val_loss: 0.2103\n",
      "Epoch 17/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9358 - loss: 0.2106 - val_accuracy: 0.9308 - val_loss: 0.2081\n",
      "Epoch 18/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9351 - loss: 0.2083 - val_accuracy: 0.9331 - val_loss: 0.2062\n",
      "Epoch 19/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9358 - loss: 0.2065 - val_accuracy: 0.9323 - val_loss: 0.2044\n",
      "Epoch 20/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9358 - loss: 0.2042 - val_accuracy: 0.9346 - val_loss: 0.2023\n",
      "Epoch 21/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9364 - loss: 0.2026 - val_accuracy: 0.9346 - val_loss: 0.2007\n",
      "Epoch 22/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9364 - loss: 0.2005 - val_accuracy: 0.9346 - val_loss: 0.1993\n",
      "Epoch 23/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9353 - loss: 0.1991 - val_accuracy: 0.9346 - val_loss: 0.1977\n",
      "Epoch 24/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9369 - loss: 0.1970 - val_accuracy: 0.9346 - val_loss: 0.1962\n",
      "Epoch 25/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9371 - loss: 0.1955 - val_accuracy: 0.9346 - val_loss: 0.1949\n",
      "Epoch 26/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9369 - loss: 0.1936 - val_accuracy: 0.9362 - val_loss: 0.1934\n",
      "Epoch 27/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9374 - loss: 0.1919 - val_accuracy: 0.9362 - val_loss: 0.1920\n",
      "Epoch 28/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9376 - loss: 0.1903 - val_accuracy: 0.9362 - val_loss: 0.1909\n",
      "Epoch 29/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9389 - loss: 0.1888 - val_accuracy: 0.9362 - val_loss: 0.1896\n",
      "Epoch 30/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9384 - loss: 0.1874 - val_accuracy: 0.9369 - val_loss: 0.1882\n",
      "Epoch 31/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9384 - loss: 0.1868 - val_accuracy: 0.9362 - val_loss: 0.1871\n",
      "Epoch 32/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9400 - loss: 0.1857 - val_accuracy: 0.9362 - val_loss: 0.1859\n",
      "Epoch 33/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9394 - loss: 0.1838 - val_accuracy: 0.9308 - val_loss: 0.1861\n",
      "Epoch 34/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9387 - loss: 0.1824 - val_accuracy: 0.9369 - val_loss: 0.1836\n",
      "Epoch 35/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9394 - loss: 0.1804 - val_accuracy: 0.9369 - val_loss: 0.1823\n",
      "Epoch 36/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9400 - loss: 0.1787 - val_accuracy: 0.9369 - val_loss: 0.1810\n",
      "Epoch 37/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9407 - loss: 0.1770 - val_accuracy: 0.9369 - val_loss: 0.1800\n",
      "Epoch 38/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9412 - loss: 0.1767 - val_accuracy: 0.9369 - val_loss: 0.1795\n",
      "Epoch 39/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9410 - loss: 0.1744 - val_accuracy: 0.9377 - val_loss: 0.1779\n",
      "Epoch 40/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9412 - loss: 0.1735 - val_accuracy: 0.9369 - val_loss: 0.1765\n",
      "Epoch 41/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9418 - loss: 0.1722 - val_accuracy: 0.9369 - val_loss: 0.1760\n",
      "Epoch 42/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9415 - loss: 0.1702 - val_accuracy: 0.9392 - val_loss: 0.1749\n",
      "Epoch 43/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9418 - loss: 0.1693 - val_accuracy: 0.9362 - val_loss: 0.1736\n",
      "Epoch 44/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9423 - loss: 0.1680 - val_accuracy: 0.9392 - val_loss: 0.1728\n",
      "Epoch 45/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9430 - loss: 0.1666 - val_accuracy: 0.9385 - val_loss: 0.1714\n",
      "Epoch 46/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9443 - loss: 0.1653 - val_accuracy: 0.9377 - val_loss: 0.1705\n",
      "Epoch 47/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9433 - loss: 0.1645 - val_accuracy: 0.9392 - val_loss: 0.1698\n",
      "Epoch 48/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9441 - loss: 0.1645 - val_accuracy: 0.9385 - val_loss: 0.1690\n",
      "Epoch 49/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9430 - loss: 0.1626 - val_accuracy: 0.9392 - val_loss: 0.1676\n",
      "Epoch 50/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9446 - loss: 0.1606 - val_accuracy: 0.9385 - val_loss: 0.1666\n",
      "Epoch 51/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9446 - loss: 0.1600 - val_accuracy: 0.9408 - val_loss: 0.1662\n",
      "Epoch 52/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9443 - loss: 0.1581 - val_accuracy: 0.9377 - val_loss: 0.1651\n",
      "Epoch 53/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9451 - loss: 0.1572 - val_accuracy: 0.9408 - val_loss: 0.1641\n",
      "Epoch 54/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9461 - loss: 0.1564 - val_accuracy: 0.9408 - val_loss: 0.1630\n",
      "Epoch 55/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9466 - loss: 0.1549 - val_accuracy: 0.9415 - val_loss: 0.1623\n",
      "Epoch 56/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9464 - loss: 0.1542 - val_accuracy: 0.9385 - val_loss: 0.1621\n",
      "Epoch 57/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9469 - loss: 0.1529 - val_accuracy: 0.9415 - val_loss: 0.1614\n",
      "Epoch 58/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9477 - loss: 0.1515 - val_accuracy: 0.9392 - val_loss: 0.1603\n",
      "Epoch 59/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9466 - loss: 0.1512 - val_accuracy: 0.9415 - val_loss: 0.1598\n",
      "Epoch 60/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9482 - loss: 0.1505 - val_accuracy: 0.9354 - val_loss: 0.1607\n",
      "Epoch 61/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9477 - loss: 0.1505 - val_accuracy: 0.9431 - val_loss: 0.1590\n",
      "Epoch 62/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9471 - loss: 0.1494 - val_accuracy: 0.9408 - val_loss: 0.1574\n",
      "Epoch 63/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9500 - loss: 0.1461 - val_accuracy: 0.9431 - val_loss: 0.1573\n",
      "Epoch 64/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9482 - loss: 0.1451 - val_accuracy: 0.9392 - val_loss: 0.1561\n",
      "Epoch 65/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9500 - loss: 0.1452 - val_accuracy: 0.9446 - val_loss: 0.1539\n",
      "Epoch 66/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9492 - loss: 0.1430 - val_accuracy: 0.9408 - val_loss: 0.1532\n",
      "Epoch 67/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9497 - loss: 0.1416 - val_accuracy: 0.9438 - val_loss: 0.1533\n",
      "Epoch 68/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9492 - loss: 0.1413 - val_accuracy: 0.9431 - val_loss: 0.1518\n",
      "Epoch 69/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9507 - loss: 0.1404 - val_accuracy: 0.9438 - val_loss: 0.1503\n",
      "Epoch 70/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9505 - loss: 0.1392 - val_accuracy: 0.9415 - val_loss: 0.1500\n",
      "Epoch 71/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9507 - loss: 0.1378 - val_accuracy: 0.9462 - val_loss: 0.1498\n",
      "Epoch 72/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9512 - loss: 0.1373 - val_accuracy: 0.9400 - val_loss: 0.1498\n",
      "Epoch 73/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9512 - loss: 0.1361 - val_accuracy: 0.9454 - val_loss: 0.1477\n",
      "Epoch 74/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9518 - loss: 0.1350 - val_accuracy: 0.9431 - val_loss: 0.1472\n",
      "Epoch 75/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9525 - loss: 0.1342 - val_accuracy: 0.9438 - val_loss: 0.1455\n",
      "Epoch 76/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9518 - loss: 0.1340 - val_accuracy: 0.9415 - val_loss: 0.1457\n",
      "Epoch 77/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9523 - loss: 0.1319 - val_accuracy: 0.9462 - val_loss: 0.1472\n",
      "Epoch 78/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9523 - loss: 0.1339 - val_accuracy: 0.9415 - val_loss: 0.1464\n",
      "Epoch 79/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9536 - loss: 0.1331 - val_accuracy: 0.9446 - val_loss: 0.1421\n",
      "Epoch 80/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9525 - loss: 0.1318 - val_accuracy: 0.9469 - val_loss: 0.1425\n",
      "Epoch 81/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9541 - loss: 0.1301 - val_accuracy: 0.9438 - val_loss: 0.1418\n",
      "Epoch 82/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9548 - loss: 0.1268 - val_accuracy: 0.9454 - val_loss: 0.1392\n",
      "Epoch 83/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9546 - loss: 0.1253 - val_accuracy: 0.9462 - val_loss: 0.1389\n",
      "Epoch 84/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9556 - loss: 0.1238 - val_accuracy: 0.9462 - val_loss: 0.1369\n",
      "Epoch 85/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9551 - loss: 0.1229 - val_accuracy: 0.9462 - val_loss: 0.1360\n",
      "Epoch 86/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9556 - loss: 0.1222 - val_accuracy: 0.9446 - val_loss: 0.1351\n",
      "Epoch 87/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9566 - loss: 0.1212 - val_accuracy: 0.9446 - val_loss: 0.1361\n",
      "Epoch 88/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9554 - loss: 0.1208 - val_accuracy: 0.9454 - val_loss: 0.1355\n",
      "Epoch 89/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9566 - loss: 0.1194 - val_accuracy: 0.9454 - val_loss: 0.1322\n",
      "Epoch 90/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9566 - loss: 0.1176 - val_accuracy: 0.9462 - val_loss: 0.1319\n",
      "Epoch 91/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9574 - loss: 0.1166 - val_accuracy: 0.9462 - val_loss: 0.1309\n",
      "Epoch 92/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9574 - loss: 0.1158 - val_accuracy: 0.9462 - val_loss: 0.1305\n",
      "Epoch 93/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9571 - loss: 0.1147 - val_accuracy: 0.9469 - val_loss: 0.1291\n",
      "Epoch 94/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9574 - loss: 0.1137 - val_accuracy: 0.9469 - val_loss: 0.1286\n",
      "Epoch 95/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9582 - loss: 0.1128 - val_accuracy: 0.9462 - val_loss: 0.1279\n",
      "Epoch 96/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9582 - loss: 0.1119 - val_accuracy: 0.9477 - val_loss: 0.1267\n",
      "Epoch 97/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9595 - loss: 0.1114 - val_accuracy: 0.9477 - val_loss: 0.1266\n",
      "Epoch 98/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9592 - loss: 0.1102 - val_accuracy: 0.9492 - val_loss: 0.1262\n",
      "Epoch 99/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9579 - loss: 0.1093 - val_accuracy: 0.9485 - val_loss: 0.1252\n",
      "Epoch 100/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9595 - loss: 0.1089 - val_accuracy: 0.9492 - val_loss: 0.1241\n",
      "Epoch 101/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9595 - loss: 0.1083 - val_accuracy: 0.9492 - val_loss: 0.1234\n",
      "Epoch 102/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9597 - loss: 0.1071 - val_accuracy: 0.9500 - val_loss: 0.1240\n",
      "Epoch 103/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9592 - loss: 0.1064 - val_accuracy: 0.9523 - val_loss: 0.1253\n",
      "Epoch 104/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9602 - loss: 0.1072 - val_accuracy: 0.9500 - val_loss: 0.1221\n",
      "Epoch 105/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9602 - loss: 0.1055 - val_accuracy: 0.9500 - val_loss: 0.1207\n",
      "Epoch 106/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9607 - loss: 0.1036 - val_accuracy: 0.9515 - val_loss: 0.1198\n",
      "Epoch 107/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9613 - loss: 0.1033 - val_accuracy: 0.9523 - val_loss: 0.1187\n",
      "Epoch 108/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9618 - loss: 0.1021 - val_accuracy: 0.9546 - val_loss: 0.1177\n",
      "Epoch 109/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9623 - loss: 0.1018 - val_accuracy: 0.9515 - val_loss: 0.1193\n",
      "Epoch 110/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9620 - loss: 0.1028 - val_accuracy: 0.9546 - val_loss: 0.1161\n",
      "Epoch 111/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9607 - loss: 0.1010 - val_accuracy: 0.9569 - val_loss: 0.1202\n",
      "Epoch 112/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9625 - loss: 0.1004 - val_accuracy: 0.9546 - val_loss: 0.1169\n",
      "Epoch 113/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9641 - loss: 0.0989 - val_accuracy: 0.9569 - val_loss: 0.1142\n",
      "Epoch 114/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9641 - loss: 0.0988 - val_accuracy: 0.9562 - val_loss: 0.1147\n",
      "Epoch 115/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9656 - loss: 0.0954 - val_accuracy: 0.9585 - val_loss: 0.1119\n",
      "Epoch 116/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9672 - loss: 0.0945 - val_accuracy: 0.9600 - val_loss: 0.1111\n",
      "Epoch 117/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9684 - loss: 0.0944 - val_accuracy: 0.9600 - val_loss: 0.1077\n",
      "Epoch 118/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9682 - loss: 0.0918 - val_accuracy: 0.9585 - val_loss: 0.1125\n",
      "Epoch 119/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9682 - loss: 0.0918 - val_accuracy: 0.9615 - val_loss: 0.1039\n",
      "Epoch 120/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9715 - loss: 0.0873 - val_accuracy: 0.9638 - val_loss: 0.1000\n",
      "Epoch 121/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9728 - loss: 0.0855 - val_accuracy: 0.9638 - val_loss: 0.0984\n",
      "Epoch 122/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9731 - loss: 0.0843 - val_accuracy: 0.9669 - val_loss: 0.0975\n",
      "Epoch 123/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9733 - loss: 0.0839 - val_accuracy: 0.9685 - val_loss: 0.0960\n",
      "Epoch 124/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9733 - loss: 0.0829 - val_accuracy: 0.9692 - val_loss: 0.0959\n",
      "Epoch 125/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9746 - loss: 0.0809 - val_accuracy: 0.9677 - val_loss: 0.0949\n",
      "Epoch 126/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9738 - loss: 0.0805 - val_accuracy: 0.9654 - val_loss: 0.0945\n",
      "Epoch 127/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9746 - loss: 0.0798 - val_accuracy: 0.9700 - val_loss: 0.0928\n",
      "Epoch 128/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9746 - loss: 0.0786 - val_accuracy: 0.9700 - val_loss: 0.0925\n",
      "Epoch 129/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9751 - loss: 0.0779 - val_accuracy: 0.9692 - val_loss: 0.0916\n",
      "Epoch 130/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9746 - loss: 0.0775 - val_accuracy: 0.9692 - val_loss: 0.0921\n",
      "Epoch 131/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9779 - loss: 0.0766 - val_accuracy: 0.9700 - val_loss: 0.0907\n",
      "Epoch 132/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9766 - loss: 0.0761 - val_accuracy: 0.9708 - val_loss: 0.0909\n",
      "Epoch 133/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9741 - loss: 0.0786 - val_accuracy: 0.9738 - val_loss: 0.0903\n",
      "Epoch 134/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9769 - loss: 0.0767 - val_accuracy: 0.9731 - val_loss: 0.0891\n",
      "Epoch 135/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9769 - loss: 0.0745 - val_accuracy: 0.9677 - val_loss: 0.0911\n",
      "Epoch 136/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9769 - loss: 0.0736 - val_accuracy: 0.9700 - val_loss: 0.0894\n",
      "Epoch 137/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9766 - loss: 0.0730 - val_accuracy: 0.9715 - val_loss: 0.0868\n",
      "Epoch 138/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9774 - loss: 0.0723 - val_accuracy: 0.9715 - val_loss: 0.0864\n",
      "Epoch 139/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9772 - loss: 0.0711 - val_accuracy: 0.9708 - val_loss: 0.0857\n",
      "Epoch 140/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9777 - loss: 0.0707 - val_accuracy: 0.9731 - val_loss: 0.0875\n",
      "Epoch 141/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9787 - loss: 0.0709 - val_accuracy: 0.9715 - val_loss: 0.0876\n",
      "Epoch 142/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9764 - loss: 0.0740 - val_accuracy: 0.9715 - val_loss: 0.0851\n",
      "Epoch 143/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9761 - loss: 0.0720 - val_accuracy: 0.9731 - val_loss: 0.0866\n",
      "Epoch 144/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9790 - loss: 0.0699 - val_accuracy: 0.9723 - val_loss: 0.0911\n",
      "Epoch 145/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9782 - loss: 0.0724 - val_accuracy: 0.9738 - val_loss: 0.0853\n",
      "Epoch 146/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9792 - loss: 0.0682 - val_accuracy: 0.9738 - val_loss: 0.0847\n",
      "Epoch 147/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9790 - loss: 0.0673 - val_accuracy: 0.9746 - val_loss: 0.0864\n",
      "Epoch 148/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9797 - loss: 0.0662 - val_accuracy: 0.9715 - val_loss: 0.0890\n",
      "Epoch 149/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9797 - loss: 0.0709 - val_accuracy: 0.9731 - val_loss: 0.0866\n",
      "Epoch 150/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9790 - loss: 0.0693 - val_accuracy: 0.9738 - val_loss: 0.0847\n",
      "Epoch 151/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9810 - loss: 0.0667 - val_accuracy: 0.9738 - val_loss: 0.0838\n",
      "Epoch 152/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9800 - loss: 0.0658 - val_accuracy: 0.9731 - val_loss: 0.0836\n",
      "Epoch 153/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9802 - loss: 0.0651 - val_accuracy: 0.9738 - val_loss: 0.0834\n",
      "Epoch 154/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9805 - loss: 0.0643 - val_accuracy: 0.9723 - val_loss: 0.0859\n",
      "Epoch 155/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9818 - loss: 0.0665 - val_accuracy: 0.9723 - val_loss: 0.0855\n",
      "Epoch 156/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9805 - loss: 0.0667 - val_accuracy: 0.9746 - val_loss: 0.0835\n",
      "Epoch 157/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9808 - loss: 0.0651 - val_accuracy: 0.9708 - val_loss: 0.0870\n",
      "Epoch 158/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9802 - loss: 0.0656 - val_accuracy: 0.9715 - val_loss: 0.0849\n",
      "Epoch 159/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9823 - loss: 0.0641 - val_accuracy: 0.9746 - val_loss: 0.0852\n",
      "Epoch 160/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9820 - loss: 0.0629 - val_accuracy: 0.9723 - val_loss: 0.0833\n",
      "Epoch 161/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9813 - loss: 0.0629 - val_accuracy: 0.9746 - val_loss: 0.0828\n",
      "Epoch 162/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9823 - loss: 0.0620 - val_accuracy: 0.9738 - val_loss: 0.0831\n",
      "Epoch 163/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9823 - loss: 0.0623 - val_accuracy: 0.9738 - val_loss: 0.0843\n",
      "Epoch 164/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9802 - loss: 0.0635 - val_accuracy: 0.9708 - val_loss: 0.0872\n",
      "Epoch 165/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9815 - loss: 0.0626 - val_accuracy: 0.9738 - val_loss: 0.0824\n",
      "Epoch 166/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9826 - loss: 0.0636 - val_accuracy: 0.9738 - val_loss: 0.0862\n",
      "Epoch 167/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9836 - loss: 0.0616 - val_accuracy: 0.9738 - val_loss: 0.0827\n",
      "Epoch 168/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9820 - loss: 0.0608 - val_accuracy: 0.9715 - val_loss: 0.0835\n",
      "Epoch 169/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9815 - loss: 0.0614 - val_accuracy: 0.9746 - val_loss: 0.0821\n",
      "Epoch 170/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9826 - loss: 0.0602 - val_accuracy: 0.9738 - val_loss: 0.0821\n",
      "Epoch 171/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9818 - loss: 0.0618 - val_accuracy: 0.9731 - val_loss: 0.0868\n",
      "Epoch 172/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9808 - loss: 0.0658 - val_accuracy: 0.9685 - val_loss: 0.0919\n",
      "Epoch 173/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9823 - loss: 0.0673 - val_accuracy: 0.9731 - val_loss: 0.0822\n",
      "Epoch 174/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9826 - loss: 0.0619 - val_accuracy: 0.9731 - val_loss: 0.0816\n",
      "Epoch 175/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9826 - loss: 0.0592 - val_accuracy: 0.9731 - val_loss: 0.0818\n",
      "Epoch 176/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9831 - loss: 0.0601 - val_accuracy: 0.9738 - val_loss: 0.0822\n",
      "Epoch 177/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9818 - loss: 0.0598 - val_accuracy: 0.9708 - val_loss: 0.0832\n",
      "Epoch 178/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9831 - loss: 0.0606 - val_accuracy: 0.9738 - val_loss: 0.0815\n",
      "Epoch 179/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9823 - loss: 0.0585 - val_accuracy: 0.9762 - val_loss: 0.0815\n",
      "Epoch 180/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9831 - loss: 0.0591 - val_accuracy: 0.9723 - val_loss: 0.0890\n",
      "Epoch 181/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9818 - loss: 0.0620 - val_accuracy: 0.9754 - val_loss: 0.0856\n",
      "Epoch 182/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9828 - loss: 0.0602 - val_accuracy: 0.9723 - val_loss: 0.0843\n",
      "Epoch 183/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9823 - loss: 0.0607 - val_accuracy: 0.9708 - val_loss: 0.0829\n",
      "Epoch 184/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9836 - loss: 0.0581 - val_accuracy: 0.9731 - val_loss: 0.0828\n",
      "Epoch 185/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9841 - loss: 0.0580 - val_accuracy: 0.9754 - val_loss: 0.0809\n",
      "Epoch 186/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9838 - loss: 0.0574 - val_accuracy: 0.9746 - val_loss: 0.0830\n",
      "Epoch 187/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9833 - loss: 0.0595 - val_accuracy: 0.9738 - val_loss: 0.0875\n",
      "Epoch 188/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9823 - loss: 0.0593 - val_accuracy: 0.9723 - val_loss: 0.0847\n",
      "Epoch 189/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9823 - loss: 0.0604 - val_accuracy: 0.9723 - val_loss: 0.0852\n",
      "Epoch 190/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9833 - loss: 0.0596 - val_accuracy: 0.9746 - val_loss: 0.0807\n",
      "Epoch 191/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9843 - loss: 0.0566 - val_accuracy: 0.9746 - val_loss: 0.0812\n",
      "Epoch 192/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9846 - loss: 0.0573 - val_accuracy: 0.9746 - val_loss: 0.0820\n",
      "Epoch 193/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9831 - loss: 0.0576 - val_accuracy: 0.9762 - val_loss: 0.0810\n",
      "Epoch 194/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9841 - loss: 0.0575 - val_accuracy: 0.9723 - val_loss: 0.0835\n",
      "Epoch 195/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9843 - loss: 0.0584 - val_accuracy: 0.9762 - val_loss: 0.0857\n",
      "Epoch 196/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9833 - loss: 0.0581 - val_accuracy: 0.9754 - val_loss: 0.0850\n",
      "Epoch 197/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9831 - loss: 0.0574 - val_accuracy: 0.9762 - val_loss: 0.0803\n",
      "Epoch 198/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9833 - loss: 0.0567 - val_accuracy: 0.9746 - val_loss: 0.0802\n",
      "Epoch 199/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9846 - loss: 0.0583 - val_accuracy: 0.9754 - val_loss: 0.0839\n",
      "Epoch 200/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9841 - loss: 0.0569 - val_accuracy: 0.9746 - val_loss: 0.0814\n",
      "Epoch 201/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9833 - loss: 0.0561 - val_accuracy: 0.9762 - val_loss: 0.0802\n",
      "Epoch 202/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9836 - loss: 0.0559 - val_accuracy: 0.9762 - val_loss: 0.0800\n",
      "Epoch 203/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9843 - loss: 0.0560 - val_accuracy: 0.9769 - val_loss: 0.0798\n",
      "Epoch 204/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9841 - loss: 0.0554 - val_accuracy: 0.9754 - val_loss: 0.0801\n",
      "Epoch 205/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9833 - loss: 0.0566 - val_accuracy: 0.9723 - val_loss: 0.0863\n",
      "Epoch 206/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9818 - loss: 0.0641 - val_accuracy: 0.9708 - val_loss: 0.0911\n",
      "Epoch 207/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9841 - loss: 0.0608 - val_accuracy: 0.9746 - val_loss: 0.0793\n",
      "Epoch 208/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9859 - loss: 0.0582 - val_accuracy: 0.9754 - val_loss: 0.0835\n",
      "Epoch 209/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9843 - loss: 0.0563 - val_accuracy: 0.9746 - val_loss: 0.0813\n",
      "Epoch 210/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9843 - loss: 0.0572 - val_accuracy: 0.9754 - val_loss: 0.0854\n",
      "Epoch 211/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9815 - loss: 0.0602 - val_accuracy: 0.9754 - val_loss: 0.0809\n",
      "Epoch 212/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9826 - loss: 0.0566 - val_accuracy: 0.9738 - val_loss: 0.0822\n",
      "Epoch 213/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9820 - loss: 0.0588 - val_accuracy: 0.9754 - val_loss: 0.0792\n",
      "Epoch 214/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9846 - loss: 0.0543 - val_accuracy: 0.9754 - val_loss: 0.0793\n",
      "Epoch 215/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9846 - loss: 0.0554 - val_accuracy: 0.9754 - val_loss: 0.0794\n",
      "Epoch 216/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9841 - loss: 0.0550 - val_accuracy: 0.9746 - val_loss: 0.0809\n",
      "Epoch 217/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9833 - loss: 0.0565 - val_accuracy: 0.9738 - val_loss: 0.0798\n",
      "Epoch 218/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9826 - loss: 0.0588 - val_accuracy: 0.9746 - val_loss: 0.0829\n",
      "Epoch 219/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9849 - loss: 0.0549 - val_accuracy: 0.9769 - val_loss: 0.0787\n",
      "Epoch 220/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9833 - loss: 0.0564 - val_accuracy: 0.9754 - val_loss: 0.0828\n",
      "Epoch 221/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9843 - loss: 0.0555 - val_accuracy: 0.9746 - val_loss: 0.0799\n",
      "Epoch 222/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9859 - loss: 0.0541 - val_accuracy: 0.9754 - val_loss: 0.0784\n",
      "Epoch 223/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9833 - loss: 0.0557 - val_accuracy: 0.9754 - val_loss: 0.0802\n",
      "Epoch 224/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9843 - loss: 0.0568 - val_accuracy: 0.9746 - val_loss: 0.0822\n",
      "Epoch 225/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9838 - loss: 0.0559 - val_accuracy: 0.9746 - val_loss: 0.0788\n",
      "Epoch 226/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9854 - loss: 0.0542 - val_accuracy: 0.9754 - val_loss: 0.0794\n",
      "Epoch 227/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9846 - loss: 0.0538 - val_accuracy: 0.9754 - val_loss: 0.0791\n",
      "Epoch 228/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9854 - loss: 0.0532 - val_accuracy: 0.9754 - val_loss: 0.0820\n",
      "Epoch 229/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9833 - loss: 0.0586 - val_accuracy: 0.9754 - val_loss: 0.0823\n",
      "Epoch 230/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9820 - loss: 0.0573 - val_accuracy: 0.9731 - val_loss: 0.0834\n",
      "Epoch 231/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9841 - loss: 0.0561 - val_accuracy: 0.9754 - val_loss: 0.0777\n",
      "Epoch 232/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9846 - loss: 0.0534 - val_accuracy: 0.9692 - val_loss: 0.0916\n",
      "Epoch 233/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9831 - loss: 0.0572 - val_accuracy: 0.9754 - val_loss: 0.0784\n",
      "Epoch 234/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9831 - loss: 0.0574 - val_accuracy: 0.9738 - val_loss: 0.0807\n",
      "Epoch 235/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9836 - loss: 0.0580 - val_accuracy: 0.9746 - val_loss: 0.0821\n",
      "Epoch 236/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9841 - loss: 0.0544 - val_accuracy: 0.9777 - val_loss: 0.0777\n",
      "Epoch 237/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9843 - loss: 0.0535 - val_accuracy: 0.9754 - val_loss: 0.0799\n",
      "Epoch 238/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9841 - loss: 0.0544 - val_accuracy: 0.9754 - val_loss: 0.0840\n",
      "Epoch 239/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9808 - loss: 0.0604 - val_accuracy: 0.9762 - val_loss: 0.0786\n",
      "Epoch 240/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9831 - loss: 0.0569 - val_accuracy: 0.9731 - val_loss: 0.0896\n",
      "Epoch 241/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9820 - loss: 0.0592 - val_accuracy: 0.9762 - val_loss: 0.0800\n",
      "Epoch 242/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9833 - loss: 0.0549 - val_accuracy: 0.9762 - val_loss: 0.0820\n",
      "Epoch 243/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9841 - loss: 0.0543 - val_accuracy: 0.9754 - val_loss: 0.0772\n",
      "Epoch 244/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9861 - loss: 0.0520 - val_accuracy: 0.9777 - val_loss: 0.0766\n",
      "Epoch 245/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9841 - loss: 0.0528 - val_accuracy: 0.9769 - val_loss: 0.0765\n",
      "Epoch 246/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9836 - loss: 0.0545 - val_accuracy: 0.9746 - val_loss: 0.0770\n",
      "Epoch 247/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9831 - loss: 0.0541 - val_accuracy: 0.9762 - val_loss: 0.0781\n",
      "Epoch 248/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9843 - loss: 0.0526 - val_accuracy: 0.9746 - val_loss: 0.0766\n",
      "Epoch 249/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9838 - loss: 0.0530 - val_accuracy: 0.9715 - val_loss: 0.0872\n",
      "Epoch 250/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9846 - loss: 0.0559 - val_accuracy: 0.9769 - val_loss: 0.0752\n",
      "Epoch 251/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9846 - loss: 0.0551 - val_accuracy: 0.9762 - val_loss: 0.0777\n",
      "Epoch 252/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9849 - loss: 0.0524 - val_accuracy: 0.9746 - val_loss: 0.0747\n",
      "Epoch 253/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9836 - loss: 0.0572 - val_accuracy: 0.9769 - val_loss: 0.0740\n",
      "Epoch 254/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9836 - loss: 0.0556 - val_accuracy: 0.9723 - val_loss: 0.0848\n",
      "Epoch 255/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9851 - loss: 0.0550 - val_accuracy: 0.9731 - val_loss: 0.0830\n",
      "Epoch 256/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9790 - loss: 0.0652 - val_accuracy: 0.9754 - val_loss: 0.0753\n",
      "Epoch 257/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9841 - loss: 0.0560 - val_accuracy: 0.9731 - val_loss: 0.0767\n",
      "Epoch 258/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9836 - loss: 0.0544 - val_accuracy: 0.9754 - val_loss: 0.0733\n",
      "Epoch 259/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9833 - loss: 0.0554 - val_accuracy: 0.9738 - val_loss: 0.0819\n",
      "Epoch 260/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9859 - loss: 0.0515 - val_accuracy: 0.9754 - val_loss: 0.0726\n",
      "Epoch 261/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9836 - loss: 0.0522 - val_accuracy: 0.9754 - val_loss: 0.0740\n",
      "Epoch 262/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9836 - loss: 0.0525 - val_accuracy: 0.9762 - val_loss: 0.0742\n",
      "Epoch 263/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9854 - loss: 0.0524 - val_accuracy: 0.9762 - val_loss: 0.0783\n",
      "Epoch 264/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9846 - loss: 0.0532 - val_accuracy: 0.9769 - val_loss: 0.0725\n",
      "Epoch 265/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9846 - loss: 0.0504 - val_accuracy: 0.9762 - val_loss: 0.0726\n",
      "Epoch 266/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9846 - loss: 0.0504 - val_accuracy: 0.9785 - val_loss: 0.0720\n",
      "Epoch 267/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9846 - loss: 0.0511 - val_accuracy: 0.9769 - val_loss: 0.0764\n",
      "Epoch 268/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9854 - loss: 0.0515 - val_accuracy: 0.9769 - val_loss: 0.0722\n",
      "Epoch 269/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9841 - loss: 0.0517 - val_accuracy: 0.9769 - val_loss: 0.0719\n",
      "Epoch 270/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9856 - loss: 0.0501 - val_accuracy: 0.9762 - val_loss: 0.0743\n",
      "Epoch 271/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9854 - loss: 0.0526 - val_accuracy: 0.9769 - val_loss: 0.0722\n",
      "Epoch 272/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9849 - loss: 0.0520 - val_accuracy: 0.9762 - val_loss: 0.0796\n",
      "Epoch 273/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9859 - loss: 0.0516 - val_accuracy: 0.9754 - val_loss: 0.0732\n",
      "Epoch 274/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9851 - loss: 0.0497 - val_accuracy: 0.9769 - val_loss: 0.0724\n",
      "Epoch 275/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9854 - loss: 0.0505 - val_accuracy: 0.9762 - val_loss: 0.0733\n",
      "Epoch 276/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9859 - loss: 0.0512 - val_accuracy: 0.9762 - val_loss: 0.0721\n",
      "Epoch 277/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9846 - loss: 0.0509 - val_accuracy: 0.9762 - val_loss: 0.0735\n",
      "Epoch 278/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9849 - loss: 0.0515 - val_accuracy: 0.9762 - val_loss: 0.0745\n",
      "Epoch 279/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9841 - loss: 0.0511 - val_accuracy: 0.9754 - val_loss: 0.0732\n",
      "Epoch 280/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9856 - loss: 0.0505 - val_accuracy: 0.9754 - val_loss: 0.0729\n",
      "Epoch 281/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9859 - loss: 0.0499 - val_accuracy: 0.9738 - val_loss: 0.0812\n",
      "Epoch 282/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9823 - loss: 0.0558 - val_accuracy: 0.9769 - val_loss: 0.0718\n",
      "Epoch 283/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9854 - loss: 0.0510 - val_accuracy: 0.9754 - val_loss: 0.0721\n",
      "Epoch 284/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9833 - loss: 0.0505 - val_accuracy: 0.9785 - val_loss: 0.0712\n",
      "Epoch 285/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9861 - loss: 0.0506 - val_accuracy: 0.9762 - val_loss: 0.0777\n",
      "Epoch 286/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9854 - loss: 0.0519 - val_accuracy: 0.9769 - val_loss: 0.0749\n",
      "Epoch 287/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9843 - loss: 0.0502 - val_accuracy: 0.9769 - val_loss: 0.0707\n",
      "Epoch 288/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9851 - loss: 0.0492 - val_accuracy: 0.9762 - val_loss: 0.0720\n",
      "Epoch 289/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9854 - loss: 0.0491 - val_accuracy: 0.9762 - val_loss: 0.0723\n",
      "Epoch 290/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9854 - loss: 0.0497 - val_accuracy: 0.9762 - val_loss: 0.0718\n",
      "Epoch 291/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9851 - loss: 0.0502 - val_accuracy: 0.9769 - val_loss: 0.0712\n",
      "Epoch 292/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9843 - loss: 0.0490 - val_accuracy: 0.9769 - val_loss: 0.0716\n",
      "Epoch 293/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9849 - loss: 0.0499 - val_accuracy: 0.9769 - val_loss: 0.0709\n",
      "Epoch 294/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9861 - loss: 0.0486 - val_accuracy: 0.9754 - val_loss: 0.0720\n",
      "Epoch 295/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9856 - loss: 0.0486 - val_accuracy: 0.9754 - val_loss: 0.0728\n",
      "Epoch 296/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9849 - loss: 0.0489 - val_accuracy: 0.9769 - val_loss: 0.0752\n",
      "Epoch 297/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9851 - loss: 0.0509 - val_accuracy: 0.9769 - val_loss: 0.0706\n",
      "Epoch 298/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9846 - loss: 0.0525 - val_accuracy: 0.9700 - val_loss: 0.0895\n",
      "Epoch 299/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9854 - loss: 0.0526 - val_accuracy: 0.9762 - val_loss: 0.0736\n",
      "Epoch 300/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9843 - loss: 0.0490 - val_accuracy: 0.9769 - val_loss: 0.0702\n",
      "Epoch 301/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9856 - loss: 0.0495 - val_accuracy: 0.9762 - val_loss: 0.0714\n",
      "Epoch 302/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9846 - loss: 0.0508 - val_accuracy: 0.9785 - val_loss: 0.0706\n",
      "Epoch 303/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9856 - loss: 0.0483 - val_accuracy: 0.9769 - val_loss: 0.0715\n",
      "Epoch 304/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9851 - loss: 0.0489 - val_accuracy: 0.9769 - val_loss: 0.0705\n",
      "Epoch 305/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9856 - loss: 0.0489 - val_accuracy: 0.9769 - val_loss: 0.0731\n",
      "Epoch 306/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9851 - loss: 0.0500 - val_accuracy: 0.9777 - val_loss: 0.0754\n",
      "Epoch 307/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9859 - loss: 0.0490 - val_accuracy: 0.9769 - val_loss: 0.0698\n",
      "Epoch 308/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9856 - loss: 0.0486 - val_accuracy: 0.9769 - val_loss: 0.0708\n",
      "Epoch 309/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9867 - loss: 0.0484 - val_accuracy: 0.9777 - val_loss: 0.0705\n",
      "Epoch 310/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9864 - loss: 0.0482 - val_accuracy: 0.9762 - val_loss: 0.0706\n",
      "Epoch 311/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9836 - loss: 0.0497 - val_accuracy: 0.9762 - val_loss: 0.0701\n",
      "Epoch 312/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9867 - loss: 0.0475 - val_accuracy: 0.9777 - val_loss: 0.0751\n",
      "Epoch 313/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9854 - loss: 0.0511 - val_accuracy: 0.9769 - val_loss: 0.0730\n",
      "Epoch 314/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9861 - loss: 0.0494 - val_accuracy: 0.9769 - val_loss: 0.0699\n",
      "Epoch 315/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9849 - loss: 0.0479 - val_accuracy: 0.9769 - val_loss: 0.0695\n",
      "Epoch 316/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9856 - loss: 0.0476 - val_accuracy: 0.9785 - val_loss: 0.0700\n",
      "Epoch 317/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9867 - loss: 0.0475 - val_accuracy: 0.9769 - val_loss: 0.0761\n",
      "Epoch 318/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9854 - loss: 0.0497 - val_accuracy: 0.9769 - val_loss: 0.0697\n",
      "Epoch 319/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9861 - loss: 0.0474 - val_accuracy: 0.9777 - val_loss: 0.0704\n",
      "Epoch 320/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9849 - loss: 0.0473 - val_accuracy: 0.9785 - val_loss: 0.0699\n",
      "Epoch 321/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9851 - loss: 0.0488 - val_accuracy: 0.9769 - val_loss: 0.0719\n",
      "Epoch 322/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9859 - loss: 0.0473 - val_accuracy: 0.9769 - val_loss: 0.0699\n",
      "Epoch 323/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9861 - loss: 0.0481 - val_accuracy: 0.9769 - val_loss: 0.0709\n",
      "Epoch 324/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9856 - loss: 0.0478 - val_accuracy: 0.9785 - val_loss: 0.0715\n",
      "Epoch 325/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9861 - loss: 0.0476 - val_accuracy: 0.9769 - val_loss: 0.0706\n",
      "Epoch 326/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9859 - loss: 0.0476 - val_accuracy: 0.9777 - val_loss: 0.0751\n",
      "Epoch 327/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9841 - loss: 0.0507 - val_accuracy: 0.9769 - val_loss: 0.0699\n",
      "Epoch 328/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9854 - loss: 0.0478 - val_accuracy: 0.9785 - val_loss: 0.0701\n",
      "Epoch 329/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9854 - loss: 0.0490 - val_accuracy: 0.9777 - val_loss: 0.0696\n",
      "Epoch 330/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9851 - loss: 0.0473 - val_accuracy: 0.9777 - val_loss: 0.0704\n",
      "Epoch 331/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9856 - loss: 0.0472 - val_accuracy: 0.9777 - val_loss: 0.0695\n",
      "Epoch 332/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9854 - loss: 0.0476 - val_accuracy: 0.9769 - val_loss: 0.0727\n",
      "Epoch 333/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9854 - loss: 0.0479 - val_accuracy: 0.9785 - val_loss: 0.0696\n",
      "Epoch 334/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9867 - loss: 0.0475 - val_accuracy: 0.9754 - val_loss: 0.0798\n",
      "Epoch 335/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9859 - loss: 0.0509 - val_accuracy: 0.9769 - val_loss: 0.0749\n",
      "Epoch 336/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9841 - loss: 0.0510 - val_accuracy: 0.9785 - val_loss: 0.0702\n",
      "Epoch 337/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9861 - loss: 0.0500 - val_accuracy: 0.9777 - val_loss: 0.0699\n",
      "Epoch 338/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9831 - loss: 0.0529 - val_accuracy: 0.9777 - val_loss: 0.0693\n",
      "Epoch 339/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9856 - loss: 0.0490 - val_accuracy: 0.9769 - val_loss: 0.0697\n",
      "Epoch 340/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9836 - loss: 0.0483 - val_accuracy: 0.9777 - val_loss: 0.0694\n",
      "Epoch 341/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9861 - loss: 0.0465 - val_accuracy: 0.9777 - val_loss: 0.0692\n",
      "Epoch 342/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9859 - loss: 0.0484 - val_accuracy: 0.9769 - val_loss: 0.0775\n",
      "Epoch 343/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9864 - loss: 0.0475 - val_accuracy: 0.9762 - val_loss: 0.0689\n",
      "Epoch 344/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9856 - loss: 0.0473 - val_accuracy: 0.9785 - val_loss: 0.0714\n",
      "Epoch 345/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9849 - loss: 0.0489 - val_accuracy: 0.9785 - val_loss: 0.0716\n",
      "Epoch 346/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9856 - loss: 0.0472 - val_accuracy: 0.9777 - val_loss: 0.0694\n",
      "Epoch 347/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9864 - loss: 0.0461 - val_accuracy: 0.9785 - val_loss: 0.0696\n",
      "Epoch 348/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9874 - loss: 0.0464 - val_accuracy: 0.9777 - val_loss: 0.0734\n",
      "Epoch 349/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9843 - loss: 0.0484 - val_accuracy: 0.9769 - val_loss: 0.0685\n",
      "Epoch 350/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9859 - loss: 0.0483 - val_accuracy: 0.9777 - val_loss: 0.0690\n",
      "Epoch 351/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9861 - loss: 0.0468 - val_accuracy: 0.9777 - val_loss: 0.0694\n",
      "Epoch 352/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9872 - loss: 0.0471 - val_accuracy: 0.9769 - val_loss: 0.0710\n",
      "Epoch 353/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9856 - loss: 0.0494 - val_accuracy: 0.9769 - val_loss: 0.0711\n",
      "Epoch 354/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9854 - loss: 0.0488 - val_accuracy: 0.9754 - val_loss: 0.0793\n",
      "Epoch 355/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9854 - loss: 0.0510 - val_accuracy: 0.9762 - val_loss: 0.0772\n",
      "Epoch 356/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9851 - loss: 0.0486 - val_accuracy: 0.9769 - val_loss: 0.0686\n",
      "Epoch 357/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9864 - loss: 0.0463 - val_accuracy: 0.9792 - val_loss: 0.0696\n",
      "Epoch 358/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9864 - loss: 0.0458 - val_accuracy: 0.9792 - val_loss: 0.0698\n",
      "Epoch 359/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9849 - loss: 0.0462 - val_accuracy: 0.9777 - val_loss: 0.0693\n",
      "Epoch 360/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9874 - loss: 0.0461 - val_accuracy: 0.9777 - val_loss: 0.0697\n",
      "Epoch 361/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9861 - loss: 0.0459 - val_accuracy: 0.9769 - val_loss: 0.0700\n",
      "Epoch 362/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9864 - loss: 0.0468 - val_accuracy: 0.9777 - val_loss: 0.0735\n",
      "Epoch 363/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9867 - loss: 0.0465 - val_accuracy: 0.9769 - val_loss: 0.0687\n",
      "Epoch 364/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9864 - loss: 0.0468 - val_accuracy: 0.9769 - val_loss: 0.0723\n",
      "Epoch 365/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9864 - loss: 0.0484 - val_accuracy: 0.9769 - val_loss: 0.0712\n",
      "Epoch 366/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9856 - loss: 0.0467 - val_accuracy: 0.9777 - val_loss: 0.0703\n",
      "Epoch 367/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9846 - loss: 0.0497 - val_accuracy: 0.9777 - val_loss: 0.0748\n",
      "Epoch 368/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9861 - loss: 0.0499 - val_accuracy: 0.9723 - val_loss: 0.0850\n",
      "Epoch 369/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9859 - loss: 0.0492 - val_accuracy: 0.9777 - val_loss: 0.0688\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#1. 성적 안오르면 20번 기다렸다가 멈춰!(브레이크 만들기)\n",
    "#학습이 언제 자동 중단될지를 설정 (이전 그래프에서 빨간 점이 다시 올라가는 순간 학습을 멈추게 하는 자동 브레이크)\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=20)\n",
    "# val_loss라는 학습 문제말고 모의고사 오차만 모니터링\n",
    "# patience=20: 20번 연속으로 val_loss가 떨어지지 않으면 학습 중단\n",
    "\n",
    "#2. 성적이 좋을 때마다  저장!(저장 장치 만들기)\n",
    "#최적화 모델이 저장될 폴더와 모델 이름을 정함\n",
    "modelpath = './data/model/bestmodel.keras'\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=0, save_best_only = True)\n",
    "#모델 실행 \n",
    "#2000번 학습 , 500개씩 학습, 25%는 모의고사, callbacks=[early_stopping_callback, checkpointer]: 조기 종료, 최적화 모델 저장\n",
    "history=model.fit(X_train, Y_train,  epochs=2000, batch_size=500, validation_split=0.25, verbose=1, callbacks=[early_stopping_callback, checkpointer])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389f7262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 975us/step - accuracy: 0.9838 - loss: 0.0453\n",
      "Test accuracy: 0.983846127986908\n"
     ]
    }
   ],
   "source": [
    "#테스트 결과 출력 \n",
    "score = model.evaluate(X_test, Y_test)\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc948c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
